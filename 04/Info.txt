Про джойны, про map side join, про Distributed Cache

Про драйвер прочитать в книге

Драйвер, что он в себя включает. Хадуп предоставляет класс ToolRunner и интерфейс Tool, которые упрощают запуск Job'а.
То есть у класса ToolRunner есть метод run, в который передаются 3 параметра

И с этого момента начинается выполнение вашего стейджа

т.е в этом драфвере вы указываете всю конфигурацию, а самое основное для Драфера чтотнеобходимо:
для начала вы должны написать свой драйвер, так как по умолчанию нет никакой конфигурации. Или хадуп запустит стандартное 

Для написания собственного драйвера необходимо наследовать класс Configured из apache.Hadoop.conf и реализовать интерфейс Tool

Далее мы должны переопределить метод run
Это тот тметод, который будет выполняться для вашего стейджа.

Причем для каждого стейджа свой драйвер пишется. Маппер, редьюсер и добаляется драйвер в первый стейдж.

////

Далее вы переопределяете метод run, указываете необходимые параметры, основные, которые должны быть
Вы создаете также экземпляр класса JobConf или просто Job - не помню, как в нвоом
И далее вызываете методы этого класса, вот например SetJoarByClass - вы туда передаете класс своего драйвера, то есть указываете на класс, который будет использовать хадуп для выполнения джоба. То есть когда он перейдет туда, он увидит такой-то драйвер, ок, я выполняю такое задание.

Далее указываете там редьюсер через setReducer
Указываете входные ключ и значение для редьюсера, а точнее setMapOutputKeyClass и Value Class

То есть вы указываете выходные ключ-значение из вашего маппера и указываете setReducer Class также и также Output Key Class Value и Key из вашего редьюсера, то есть пара ключ и значение, выходящая с редьюсера.

Там есть подробнее в книжке
все что необходимо в драйвере

Потом вы указываете формат OutputFormatClass то есть формат вашего выходного файла - sequence файл или Text файл
вот в примере увидите там TextInputFormat
и там просто метод AddPath
То есть указываете, что будет текстовый файл и путь до него


Это основные методы которые вызвать и передать параметры, чтобы все работало
Если не укажете редьюсер, запустится редьюсер по умолчанию, и задача упадет, не найдя соответствие.


И еще один обязательный метод WaitForComplation
то есть он запускает джоб на кластере и ожидает его возвращения
Возвращеет true успешно или false
Еще он принимает параметр будевского типа - если указываете true, то информация о выполнении выводится в консоль

То есть логи увидим просто.

Остальные методы, которые там есть, по их названию все понятно. Есть дополнительные, но их можно найти. Какие нам нужны, я буду говорить.


////////


Есть еще такой инструмент, как map side join
Он прекрасно подходит для джойна входных файлов по какому-либо ключу перед подачей на вход мапперу.

То есть если у вас есть два разных файла - два разных источника, и вы хотите сразу объединить их строки по какому-либо ключу, то есть сделать джойн этих двух источников, то можно использовать такой инструмент

Для этого в дрйвере в методе setInputFormat вы должны в качестве параметра указать CompositeInputFormat
То есть обычно вы указываете либо TextInputFormat, а тут вот так.

Далее вызываете метод из класса CompositeInputeFormat, метод называется Compose(), который получает 3 параметра:
1 - String (то есть Option)
2 - передаете класс, который наследуется от InputFormat, ну то есть это TextFile либо SequenceFile
3 - и все остальные значения вы передаете там просто уже идут переменные переменного типа, то есть вы передаете пути до ваших файлов, которые будут джойниться, 

тип возвращаемого значения у этого метода String

(стр.370

Для выполнения соединения на стороне отображения используется класс Compos-
iteInputFormat из пакета org.apache.hadoop.mapreduce.join . Источники ввода
и тип соединения (внутреннее или внешнее) для CompositeInputFormat настраи­
ваются через выражение соединения, написанное по простой схеме. Подробности
и примеры приведены в документации пакета.
Пример org.apache.hadoop.examples.Join — программа общего назначения, ра­
ботающая в режиме командной строки и предназначенная для выполнения соеди­
нений на стороне отображения. Она позволяет запустить задание MapReduce для
любой заданной функции отображения и свертки для нескольких соединяемых
источников данных.)

Итак, в чем вообще смысл вот этого.
Мы вообще очень редко пользуемся map side join, так как мало людей, которые о нем знают, либо пока не было таких задач.


/////

Option может принимать значения:
- inner - то есть один к одному, если совпали, 
- outer - это фулл джойн
- override - что-то похожее на left join, но когда мы указыаем, получается совпадение, то есть там взаимоисключающиеся джойнит
(можете сами попробовать)

///

Класс, который должен наследоваться от InputFormat
Вам необходимо будет переопределить еще два класса:
1 - RecordReader для вашей конкретной задачи, потому что по умолчанию он сам разбрает какой тип входящего файла, если текст, он разбивает на ключ интовое значение, и текстовое,
и все передается на вход маппера
А если сиквенс, то ключ отделяет и значение

Но! RecordReader вам нужно будет, если вы хотите джойнить ваши источники по какому-то полю, допустим, оно второе по =счету, то нужно будет переопределить и вытащить это поле и поместить в качестве ключа, по которому он должен джойнить, и передать в качестве ключа, или же несколько полей.

2 - и ван надо будет переопределить FileInputFormat, там ничего не меняется, только в нем поменять тип возвращаемого вашего RecordReader класса, который вы переопределили.

Поэтому вот и получается, что вы два класса переопределяете.

И последний переопределенный класс FileInputForfard вы в качестве аргумента передаете в метод Compose()

///

И последний параметр, это входные данные грубо говоря. То есть у вас две таблицы, то там будут пути до этих двух таблиц через запятую.


И еще, после того, как вы получается вызвали этот метод, он возвращает стрингу (конфиг какой-то),
также после этого вы указываете в конфигурации есть получается название конфига MapRegJoinExp
Это вы найдете, не буду дословно называть его
Просто вы указываете, что вот в этот конфиг, то он join есть и указываете тип, который возвратил у вас метод compose. и тогда он сам подтянет и все ок будет.


Главное тут запомнить, что map side join - это джойн двух файлов до их подачи на редьюсер.


/////////////////////


И теперь будем рассматривать side data distribution
На него и будет ваше следующее ДЗ

side data используется для чтения данных, необходимых во время обработки основгых данных.
Задача side data (distributed cache) состоит в том, чтобы обеспечить доступ к каим-то данныхм на стадиях мап и редьюс.

То есть side data копируется на каждую ноду, где выполняется стейдж либо мап, либо редьюс, поэтому логично предположить, что эти данные должны быть небольшого размера. 
Потому что он считывает этот файлик и полностью дублирует на все ноды, где будут выполняться ваши таски.

Иначе проще его еще одним маппером считать и потом соединить, или долго будет, или завалится. 

По сути, мы берем маленький справочник, раскидываем его на все ноды, где таски выполняются, и во время работы погружаем его в оперативку, зписываем его в коллекцию, чаще это HashMap или просто Map

Потом, когда начинается стадия мап, мы обрабатываем одну строку, выцепливаем айдишник, и достаем из мапы по этому айдишнику из словаря то что надо, и отправляем данные данные.


ТО ЕСТЬ map side join - ДО обработки,
а distributed cache (side data) - он уже непосредственно на редьюсере работает (либо на маппере) - и там, и там можно использовать, данные на каждой ноде сохраняются локально, можно поэтому использовать на любой стадии.

В качестве таких файлов можно использовать и тексты, и архивы, и jar

Для использования distributed cashe файлов достаточно просто в классе драйвер опять же вызвать метод addCacheFile()
Это значит, вы создаете там экземпляр класса Job основной, который указывает все параметры, необходимые для вашего джоба. В примемре в книге есть

В качестве аргумента в метрод передать просто путь до вашего класса

Далее в классе маппер или редьюсере в методе setup вы можете получить доступ к этим файлам. Метод Setup() принимает один параметр - это контекст
Он несет с собой всю инфу о вашем джобе, записывает если что данныеЮ также вы можете получить и конфигурационные какие-то моменты, протсо вызвав нужный метод

И вы просто в данном случае getCacheFile который возвращает массив url-ов

Ну а дальше у вас считывание данных происходит как будто с локального коммьютере читаете файл, только не нужно забывать от форматах хранения. Допустим есть CacheFile в виде Sequence file, то нужно вызвать SequenceFileReader
И правильно упаковать и распаковать в ключ-значение.


НУ и методы Setup и Clear еще есть в классах Mapper и Reducer
Эти методы вызываются только по одному разу для кажого таска на стадиях мапа и редьюса.
То есть методж setup выхывается до начала стадии, а clear - после завершения выхывается.


Метод setup мы довольно часто вызываем, потому что если нам надо проинициализировтаь наш класс параметрами, которые передавались, то есть вытащить оттуда дуту, которая передавалась, ну и для CachFile'ов

Метод clear оччень редко встречается, особо его никто не вызывает. 

Сетап - до того, как маппер начал считывать строчкц, он вызывается один раз, то есть в нем можно проинициализировать какие-то глобальные переменные, которые вы будете использовать для расчета. И успокоиться. Вот пока маппер считывает строки, эти переменные будут ему доступны, он будет обращаться к одной и той же переменной.

И да, кстати, чтобы ошибку не допустить. Сетап один раз для каждого таска вызывается.
и Clear после того, как маппер иоли редьюсер отработал, он вызывается один раз.

//////

ДЗ
Тестовый класс
Драйвер, у него WithFile
просто передаете туда этот файл как параметр

И можно следующую тему: заключительная пара по мапРедьюсу
SecondarySort дома посмотреть

Если кто почитает (три класса переопределить), если кто поймет, то написать лично, дам ему дз и он попробует сам реализовать.
Это будет дополнительным плюсом.




